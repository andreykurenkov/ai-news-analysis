---
title: "Last Week in AI #41"
excerpt: "AI in psychiatry, Sony's new AI lab, and more!"
image:
  feature: assets/img/digests/41/main.jpg
  credit: <a href="https://time.com/5727535/artificial-intelligence-psychiatry/"> Jamie Ducharme / TIME </a>
categories: [digests]
permalink: /digests/the-forty-first
---

### Mini Briefs

#### [Artificial Intelligence Could Help Solve America's Impending Mental Health Crisis](https://time.com/5727535/artificial-intelligence-psychiatry/)

The US's already overburdened mental health system may be short by over 10,000 psychiatrists in the next five years, but some proponents believe AI may help mental health practitioners mitigate the impact of the deficit. While psychiatry requires emotional intelligence and perception that AI software lack, the field may yet benefit from AI's ability to analyze data and pick up on the patterns and warning signs that humans overlook.

Time-restricted clinicians may be able to use AI to make the best of their time with patients and bridge gaps in access. AI-aided data analysis could facilitate quicker and more accurate diagnoses, for example. Because of its promise, a number of researchers are exploring the various potential uses of AI in psychiatry.

#### [It's Sony AI vs. Facebook, Google](https://www.eetimes.com/document.asp?doc_id=1335303)

Sony Corp. has launched Sony AI, a new organization to pursue advanced R&D in artificial intelligence. Intending to go head-to-head with Google and Facebook, Sony AI, which will formally start operation next month, has research sites in Tokyo, Austin, Texas, and a city in Europe. The organization is a hub of Sony's basic AI R&D, whose research results will be leveraged by AI-related projects across Sony.

Led by Hiroaki Kitano, a leading AI researcher and current president of Sony Computer Science Laboratories, Sony AI will debut with three flagship project in gaming, imaging and sensing, and gastronomy. In addition to enabling AI in Sony's business products, Sony AI will pursue "explorative research projects, including AI ethics." While Sony AI seems late to the game in launching an independent AI unit, a spokesman stressed that Sony does not see itself as a latecomer to AI R&D due to its prior engagement in a host of AI R&D projects, even if its AI prowess is not as well-publicized as Google's and Facebook's.

### Advances & Business

* [Why Is Google Slow-Walking Its Breakthroughs in AI?](https://www.wired.com/story/why-is-google-slow-walking-its-breakthroughs-in-ai/) - Google became what it is by creating advanced new technology and throwing it open to all. Giant businesses and individuals alike can use the company's search and email services, or tap its targeting algorithms and vast audience for ad campaigns. Recently, the company has begun withholding or restricting some of its AI research and services, to protect the public from misuse.

* [Google details DeepMind AI's role in Play Store app recommendations](https://venturebeat.com/2019/11/18/deepminds-ai-now-powers-google-play-store-app-recommendations/) - AI and machine learning model architectures developed by Alphabet's DeepMind have substantially improved the Google Play Store's discovery systems, according to Google.

* [Scientists have found 142 more ancient etchings in Peru. Now AI will speed up the hunt.](https://www.technologyreview.com/f/614734/scientists-have-found-142-more-ancient-etchings-in-peru-now-ai-will-help-speed-up-the-hunt/) - Located in the Nazca Desert in southern Peru, the Nazca Lines are a collection of giant etchings that only make sense from a great height. Now AI is helping speed up the hunt for more hidden symbols and has already had some success.

* [Alphabet's Dream of an 'Everyday Robot' Is Just Out of Reach](https://www.wired.com/story/alphabets-dream-everyday-robot-out-reach/) - A project called Everyday Robot at Alphabet's X Lab hopes to make robots less reliant on human coding for their skills, and capable of adapting quickly to complex new tasks and environments. Despite success at learning tasks such as sorting trash from experience, researchers such as UC Berkeley's Pieter Abbeel still question whether these results will transfer to a robot's ability to learn other tasks.

* [Stanford, UMass Amherst develop algorithms that train AI to avoid specific misbehaviors](https://news.stanford.edu/2019/11/21/stanford-helps-train-ai-not-misbehave/) - A team led by researchers at Stanford and UMass Amherst published a paper in _Science_ suggesting how to offer assurances that automated systems have been designed to minimize, if not avoid, unwanted outcomes such as excessive risk or racial and gender bias.

* [Using neural machine translation to correct grammatical faux pas in Google Docs](https://cloud.google.com/blog/products/productivity-collaboration/using-neural-machine-translation-to-correct-grammatical-in-google-docs/) - In this blog post, Google explains how research advances in language understanding, made possible by neural machine translation, are making a significant improvement in correcting langugae errors.

* [Safety Gym](https://openai.com/blog/safety-gym/) - OpenAI is releasing Safety Gym, a suite of environments and tools for measuring progress towards reinforcement learning agents that respect safety constraints while training. We also provide a standardized method of comparing algorithms and how well they avoid costly mistakes while learning.

* [Machine learning has revealed exactly how much of a Shakespeare play was written by someone else](https://www.technologyreview.com/s/614742/machine-learning-has-revealed-exactly-how-much-of-a-shakespeare-play-was-written-by-someone/) - Literary analysts have long noticed the hand of another author in Shakespeare’s Henry VIII. Now a neural network has identified the specific scenes in question—and who actually wrote them.

### Concerns & Hype

* [Here's How Knightscope's Security Robots Surveil the Public](https://onezero.medium.com/heres-how-knightscope-s-security-robots-surveil-the-public-c2c6d14ee2c2) - OneZero obtained a presentation that reveals how Knightscope uses facial recognition and license plate readers to track individuals.

* [AI will disrupt white-collar workers the most, predicts a new report](https://www.technologyreview.com/f/614739/ai-will-disrupt-white-collar-workers-the-most-predicts-a-new-report/) - A surprise finding: Conventional wisdom says robotics, artificial intelligence, and automation will radically alter work for blue-collar truckers and factory workers. In fact, white-collar jobs will be affected more, according to a new analysis by the Brookings Institution.

* [Are Neural Networks About to Reinvent Physics?](http://nautil.us/issue/78/atmospheres/are-neural-networks-about-to-reinvent-physics) - The exaggerated claims made in recent papers on the application of neural networks to problems in physics, and the resulting hype surrounding these, are symptoms of a tendency among science journalists—and sometimes scientists themselves—to overstate the significance of new advances in AI and machine learning.

* [Disability, Bias, and AI](https://medium.com/@AINowInstitute/disability-bias-and-ai-4434dc7065f0) - AI systems are being rapidly integrated into core social domains, informing decisions about who gets resources and opportunity, and who doesn't. These systems, often marketed as smarter, better, and more objective, have been shown repeatedly to produce biased and erroneous outputs. While much AI bias research and reporting has focused on race and gender, there has been much less attention paid to AI bias and disability.

* [AI dermatology tool needs more diverse skin types in its training datasets](https://physicsworld.com/a/ai-dermatology-tool-needs-more-diverse-skin-types-in-its-training-datasets/) - An artificial intelligence (AI)-powered dermatology algorithm that can identify a range of skin conditions doesn't work effectively on black skin. That's the finding of researchers in Uganda and Sweden, who tested the software on adults in Uganda.

* [The Media's Coverage of AI is Bogus](https://blogs.scientificamerican.com/observations/the-medias-coverage-of-ai-is-bogus/) - Headlines about machine learning promise godlike predictive power. It's all a lie. Machine learning can’t confidently tell such things about each individual. In most cases, these things are simply too difficult to predict with certainty.

* [AI today and tomorrow is mostly about curve fitting, not intelligence](https://diginomica.com/ai-curve-fitting-not-intelligence) - As debates around AI's value continue, the risk of an AI winter is real. We need to level set what is real and what is imagined so that the next press release you see describing some amazing breakthrough is properly contextualized.

### Analysis & Policy

* [Department of Energy Announces $15 Million for Development of Artificial Intelligence and Machine Learning Tools](https://www.energy.gov/articles/department-energy-announces-15-million-development-artificial-intelligence-and-machine) - On November 19, the U.S. Department of Energy’s (DOE’s) Advanced Research Projects Agency-Energy (ARPA-E) announced $15 million in funding for 23 projects to accelerate the incorporation of machine learning and artificial intelligence into the energy technology and product design processes as part of the Design Intelligence Fostering Formidable Energy Reduction (and) Enabling Novel Totally Impactful Advanced Technology Enhancements (DIFFERENTIATE) program.

### Expert Opinions & Discussion within the field

* [AI Academy Under Siege](https://www.insidehighered.com/views/2019/11/20/how-stop-brain-drain-artificial-intelligence-experts-out-academia-opinion) - Universities have long been a source of talented leaders for industry, but an accelerating exodus of professors with expertise in artificial intelligence has caused concerns.

* [Researchers Want Guardrails to Help Prevent Bias in AI](https://www.wired.com/story/researchers-guardrails-prevent-bias-ai/) - Artificial intelligence has given us algorithms capable of recognizing faces, diagnosing disease, and of course, crushing computer games. But even the smartest algorithms can sometimes behave in unexpected and unwanted ways, for example picking up gender bias from the text or images they are fed.

* [Bill Gates Says Open Research Beats Erecting Borders in AI](https://www.bloomberg.com/news/articles/2019-11-21/bill-gates-you-can-t-nationalize-ai-research-open-systems-win) - Microsoft Corp. co-founder Bill Gates spoke out against protectionism in technological research around topics like artificial intelligence, arguing that open systems will inevitably win out over closed ones.

### Explainers

* [Computer Vision and Visual SLAM vs. AI Agents](http://www.computervisionblog.com/2019/11/computer-vision-and-visual-slam-vs-ai.html) - With all the recent advancements in end-to-end deep learning, it is now possible to train AI agents to perform many different tasks (some in simulation and some in the real-world).

* [All The Ways You Can Compress BERT](http://mitchgordon.me/machine/learning/2019/11/18/all-the-ways-to-compress-BERT.html) - Model compression reduces redundancy in a trained neural network. This is useful, since BERT barely fits on a GPU (BERT-Large does not) and definitely won't fit on your smart phone. Improved memory and inference speed efficiency can also save costs at scale.

* [Notes on AI Bias](https://www.ben-evans.com/benedictevans/2019/4/15/notes-on-ai-bias) - Machine learning finds patterns in data. "AI Bias" means that it might find the wrong patterns - a system for spotting skin cancer might be paying more attention to whether the photo was taken in a doctor's office.


<hr>

That's all for this week! If you are not subscribed and liked this, feel free to subscribe below!
