---
title: "Last Week in AI #69"
excerpt: "Stopping police use of face recognition, #ShutdownSTEM, and more!"
image: 
  feature: assets/img/digests/69/comp-rekog4_web.jpg
  credit: <a href="<Image Source Link>"> MS TECH | GETTY via MIT Technology Review</a>
categories: [digests]
permalink: /digests/the-sixty-ninth
sidebartoc: true
---

### Mini Briefs

#### [The two-year fight to stop Amazon from selling face recognition to the police](https://www.technologyreview.com/2020/06/12/1003482/amazon-stopped-selling-police-face-recognition-fight/)

Since 2018, studies in commercial face recognition systems have consistently revealed that these products perform worse for people of color. 
For instance, a study in 2019 found that in a gender classification task, Amazon's Rekognition performed 31.4% worse for darker-skinned female faces when compared to lighter-skinned male faces.

When these flawed systems are applied by law enforcement, they can place people of color at higher risk due to the higher error rate. 
Even if these systems worked perfectly, they can still be "easily weaponized against communities to harass them."

Earlier this week, in response to recent national protests and dialogues, IBM announced it would no longer develop and offer face recognition technology. 
Microsoft followed suit, announcing that it would stop selling face recognition technology to policy departments until federal regulations were in place. 
Amazon, which initially discredited the resesarch that showed the biases in Rekognition, has also placed a one year moratorium on police use of the face recognition system.

Currently, House and Senate Democrats are introducing a police reform bill that limits face recognition in law enforcement.
Many see this bill and the recent responses from tech companies as promising starting points.
However, but more pressure is needed to ensure fair and ethical uses of face recognition and other AI technologies with significant social impacts.

Related commentary: 

* [A Case for Banning Facial Recognition](https://www.nytimes.com/2020/06/09/technology/facial-recognition-software.html) - A Google research scientist explains why she thinks the police shouldn't use facial recognition software.

* [IBM Leads, More Should Follow: Racial Justice Requires Algorithmic Justice and Funding](https://medium.com/@Joy.Buolamwini/ibm-leads-more-should-follow-racial-justice-requires-algorithmic-justice-and-funding-da47e07e5b58) - The Algorithmic Justice League commends IBM's decision to stop selling facial recognition technologies, and calls for next steps: systematic change requires resources.

* [ACLU Statement on Amazon Face Recognition Moratorium](https://www.aclu.org/press-releases/aclu-statement-amazon-face-recognition-moratorium) - ACLU commends Amazon's recognition that the dangers face recognition poses to Black and Brown communities and civil rights more broadly. 

### Podcast

Check out our weekly podcast covering these stories!
[Website](https://aitalk.podbean.com) \|
[RSS](https://feed.podbean.com/aitalk/feed.xml) \| 
[iTunes](https://podcasts.apple.com/us/podcast/lets-talk-ai/id1502782720) \|
[Spotify](https://open.spotify.com/show/17HiNdxcoKJLLNibIAyUch) \| 
[YouTube](https://www.youtube.com/channel/UCKARTq-t5SPMzwtft8FWwnA)
<iframe title="Let's Talk AI" id="multi_iframe" class="podcast_embed"
 src="https://www.podbean.com/media/player/multi?playlist=http%3A%2F%2Fplaylist.podbean.com%2F7703921%2Fplaylist_multi.xml&vjs=1&kdsowie31j4k1jlf913=4975ccdd28d39e38bf5a1ccaf0c6ca4337fa996b&size=430&skin=9&episode_list_bg=%23ffffff&bg_left=%23000000&bg_mid=%230c5056&bg_right=%232a1844&podcast_title_color=%23c4c4c4&episode_title_color=%23ffffff&auto=0&share=1&fonts=Helvetica&download=0&rtl=0&show_playlist_recent_number=10&pbad=1" 
 scrolling="yes" allowfullscreen="" width="100%" height="330" frameborder="0"></iframe>

### News
#### Advances & Business

* [Facebook's TransCoder AI converts code from one programming language into another](https://venturebeat.com/2020/06/08/facebooks-transcoder-ai-converts-code-from-one-programming-language-into-another/) - Facebook researchers say they've developed what they call a neural transcompiler, a system that converts code from one high-level programming language like C++, Java, and Python into another.

* [Research summary: Towards the Systematic Reporting of the Energy and Carbon Footprints of Machine Learning](https://montrealethics.ai/research-summary-towards-the-systematic-reporting-of-the-energy-and-carbon-footprints-of-machine-learning/) - While AI has the potential to help mitigate climate change, AI models can have excessively large carbon footprints.

* [OpenAI's Text Generator Is Going Commercial](https://www.wired.com/story/openai-text-generator-going-commercial/) - Last spring, artificial intelligence research institute OpenAI said it had made software so good at generating text - including fake news articles - that it was too dangerous to release.

* [DeepMind hopes to teach AI to cooperate by playing Diplomacy](https://venturebeat.com/2020/06/10/deepmind-hopes-to-teach-ai-to-cooperate-by-playing-diplomacy/) - DeepMind, the Alphabet-backed machine learning lab that's tackled chess, Go, Starcraft 2, Montezuma's Revenge, and beyond, believes the board game Diplomacy could motivate a promising new direction in reinforcement learning research. 

* [Working from home, with robots](https://www.theverge.com/21285010/boston-dynamics-spot-engineers-2-0-upgrade-working-from-home) - How Boston Dynamics' engineers are upgrading the company's four-legged Spot from their basements and backyards

#### Concerns & Hype

* [Scientists Call for Academic Shutdown in Support of Black Lives](https://gizmodo.com/scientists-call-for-academic-shutdown-in-support-of-bla-1843944068) - White supremacy is baked into science and academia, from racist language in textbooks to a culture that excludes Black scientists from innovating and advancing at the same pace as their colleagues. But rather than more milquetoast statements and diversity initiatives, researchers want action.

* [A U.S. Secret Weapon in A.I.: Chinese Talent](https://www.nytimes.com/2020/06/09/technology/china-ai-research-education.html) - New research shows scientists educated in China help American firms and schools dominate the cutting-edge field. Now industry leaders worry that worsening political tensions will blunt that edge.

* [Microsoft's AI journalists confuse mixed-race Little Mix singers on MSN homepage](https://www.theverge.com/2020/6/9/21284934/microsoft-ai-news-editors-msn-homepage-little-mix-singers) - Microsoft laid off dozens of human journalists at MSN last month.

* [No Recent Automation Revolution](http://www.overcomingbias.com/2020/06/no-recent-automation-revolution.html) - The big automation revolution portrayed in popular media is overhyped

* [IBM gets out of facial recognition business, calls on Congress to advance policies tackling racial injustice](https://www.cnbc.com/2020/06/08/ibm-gets-out-of-facial-recognition-business-calls-on-congress-to-advance-policies-tackling-racial-injustice.html?__source=sharebar) - IBM CEO Arvind Krishna called on Congress Monday to enact reforms to advance racial justice and combat systemic racism while announcing the company was getting out of the facial recognition business.

* [Amazon Pauses Police Use of Its Facial Recognition Software](https://www.nytimes.com/2020/06/10/technology/amazon-facial-recognition-backlash.html) - The company said it hoped the moratorium "might give Congress enough time to put in place appropriate rules" for the technology.

* [Microsoft says it won't sell facial recognition technology to US police departments](https://www.cnn.com/2020/06/11/tech/microsoft-facial-recognition-police/index.html) - Microsoft said Thursday it will not sell facial recognition technology to police departments in the United States, at least until there is a federal law to regulate the technology.

#### Expert Opinions & Discussion within the field

* [The weird, frightening future of AI may not be what you think](https://www.cnet.com/news/the-weird-frightening-future-of-ai-may-not-be-what-you-think/) - There are five principles of AI weirdness, according to author and researcher Janelle Shane. One of them is: "The danger of AI is not that it's too smart but it's not smart enough." But another is: "AI does not really understand the problem you want it to solve.

## Awesome Videos

<iframe width="560" height="315" src="https://www.youtube.com/embed/hHHCrf2-x6w" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<hr>

That's all for this week! If you are not subscribed and liked this, feel free to subscribe below!
