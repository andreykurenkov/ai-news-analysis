---
title: "Skynet This Week #4"
excerpt: "OpenAI bots, robots, surveillance, and more!"
permalink: /digests/the-fourth
categories: [digests]
---

## AI Advances
#### [A team of AI algorithms just crushed humans in a complex computer game](https://www.technologyreview.com/s/611536/a-team-of-ai-algorithms-just-crushed-expert-humans-in-a-complex-computer-game/) 
##### Will Knight, MIT Tech Review 

OpenAI has followed up on its 2017 achievement of beating pros at a 1v1 variation of the popular strategy game DoTA with a far more impressive feat: [managing to beat a team of human players at a much more complex 5v5 variation of the game](https://blog.openai.com/openai-five/). Interestingly, the achievement was reached without any algorithmic advances, as OpenAI explain:

> ‚ÄúOpenAI Five plays 180 years worth of games against itself every day, learning via self-play. It trains using a scaled-up version of Proximal Policy Optimization running on 256 GPUs and 128,000 CPU cores ... This indicates that reinforcement learning can yield long-term planning with large but achievable scale ‚Äî without fundamental advances, contrary to our own expectations upon starting the project.‚Äù

Though definitely impressive, it should be remembered that these systems took hundreds of human lifetimes to train just to play one game. So, just as with prior achievements in Go, they represent the success of present day AI at mastering single narrow skills using a ton of computation, and not the ability to match humans at learning many skills with much less experience.

#### [Don‚Äôt  Just Lecture Robots -- Make Them Learn](https://www.wired.com/story/dont-just-lecture-robotsmake-them-learn/)
##### Matt Simon, WIRED

Normally a robot has to learn everything from scratch, on its own. New research from UC Berkeley changes that - allowing robots to learn from experience and demonstrations. Matt Simon at the WIRED explains how such a systems works and what implications this has for future research. 

<hr>

## AI Worries
#### [Inside China‚Äôs Dystopian Dreams: A.I., Shame and Lots of Cameras](https://www.nytimes.com/2018/07/08/business/china-surveillance-technology.html)
##### Paul Mozur, The New York Times

In China, the police are aggressive using AI. Using a network of over 200 million surveillance cameras and even ‚Äúfacial recognition glasses,‚Äù local law enforcement is able to sweep crowded areas in the hunt for criminals. Despite the tone of this article, it is worth noting that United States law enforcement uses similar tactics such as license plate readers to perform dragnet surveillance, though such tactics are more troubling in a country of single-party rule.

#### [Facebook's DensePose Tech Raises Concerns About Potential Misuse](https://spectrum.ieee.org/tech-talk/robotics/artificial-intelligence/surveillance-concerns-follow-facebooks-densepose-tech) 
##### Jeremy Hsu, IEEE Spectrum

Facebook open sourced DensePose, a deep learning based system that can make 3D models of humans from 2D images or videos. Jack Clark from OpenAI raises concerns about how such a system could be used in real-time surveillance. It is up to the researchers to ask how their systems might be used, before releasing them to the world. 

<hr>

## The Latest on AI Policy
#### [An Overview of National AI Strategies](https://medium.com/politics-ai/an-overview-of-national-ai-strategies-2a70ec6edfd)
##### Tim Dutton, [Medium](https://medium.com/@tim.a.dutton?source=post_header_lockup)

The race to become the leading country in AI is on. Russian president Vladimir Putin has said ‚ÄúWhoever becomes the leader in this (AI) sphere will become the ruler of the world‚Äù. Various countries have developed a national strategy for AI. Tim Dutton, an AI Policy researcher at CIFAR summarizes the key policies and goals of each national strategy. It makes for an interesting read to look at and compare the various perspectives of different countries regarding AI.

#### [Regulating AI in the era of big tech](https://thegradient.pub/regulating-ai-in-the-era-of-big-tech/)
##### Melody Guan, [The Gradient](https://thegradient.pub/)

It's increasingly clear government has a role in making AI is not abused. Unfortunately, it seems the US is making little progress towards that direction:

> "Unfortunately for U.S. citizens, little change has been made by lawmakers to protect their interests. On the subject of private and ethical AI, the U.S. government has been disinterested, lacking in expertise, and impotent to stand up to tech corporations."

Let's hope more progress is made soon.

<hr>

## Expert Opinions & Discussion within the field
#### [What are radiological deep learning models actually learning?](https://medium.com/@jrzech/what-are-radiological-deep-learning-models-actually-learning-f97a546c5b98)
##### John Zech, Medium

Radiological deep learning models are identifying the type of scanner used for X-rays and weighting predictions accordingly. Specifically, the model identifies if the scanner is portable (indicated by the word ‚ÄúPORTABLE‚Äù on the radiograph) and skewing predictions accordingly. Use of portable scanners is an indication that the patient is too ill to leave the hospital bed and likely to have a disease. Check out John Zech‚Äôs blog post for the details!

#### [Troubling Trends in Machine Learning Scholarship](http://approximatelycorrect.com/2018/07/10/troubling-trends-in-machine-learning-scholarship/)
##### Zachary C. Lipton & Jacob Steinhardt, Approximately Correct

This is an accompanying blog post to an ICML 2018 debates paper by Zach Lipton and Jacob Steinhardt. They identify four patterns observed in ML scholarship which take away from making a great paper. They suggest ways to combat these patterns as a community and as an author. The aim of their work is to start an important discussion within the community as papers have a much broader audience now. 

> ‚ÄúFlawed scholarship threatens to mislead the public and stymie future research by compromising ML‚Äôs intellectual foundations. By promoting clear scientific thinking and communication, we can sustain the trust and investment currently enjoyed by our community.‚Äù

<hr>

## Awesome Videos
#### [Why artificial intelligence has no common sense](https://youtu.be/NPEPx6VUgrg)
##### Becca Farsace, The Verge

It‚Äôs easy to become desensitized to the term AI and misunderstand the current state of AI. After Google unveiled Duplex, Becca Farsace of the Verge wanted to understand the current state of the field. She talks to AI journalist James Vincent and AI expert Oren Etzioni about how close AI is to having ‚Äúcommon sense‚Äù. This is a great high level overview of what AI is capable of today, the concerns due to those capabilities, and regulation.

> ‚ÄúHow close are we to Skynet? Is that coming? No, it‚Äôs not!‚Äù

<iframe width="560" height="315" src="https://www.youtube.com/embed/NPEPx6VUgrg?rel=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>

#### [What AI have MIT been creating?](https://youtu.be/mZrmoi5D7g0)
##### Spencer Kelly, BBC Click

MIT's CSAIL is one of the leading AI research institutions in the world. This video provides a great summary of their recent exciting research -- seeing people through walls, helping people with disabilities generate more natural sounding speech with AI, and more.

<iframe width="560" height="315" src="https://www.youtube.com/embed/mZrmoi5D7g0?rel=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>

<hr>

## Explainers
#### [NLP's ImageNet moment has arrived](https://thegradient.pub/nlp-imagenet/)
##### Sebastian Ruder, The Gradient

A nice summary of exciting recent NLP research for learning better representations. 

#### [Bots & Thoughts from ICRA2018](https://blog.evjang.com/2018/06/icra2018.html)
##### Eric Jang

A fun summary of the experience of attending the 2018 ICRA conference. 

## Favourite Tweet
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Successfully training neural networks requires almost no math skills, but does require knowing a large number of otherwise useless tricks. <a href="https://t.co/3iQGYBHYCB">https://t.co/3iQGYBHYCB</a></p>&mdash; David Sussillo ‚òùÔ∏èü§ì (@SussilloDavid) <a href="https://twitter.com/SussilloDavid/status/1014217006596403201?ref_src=twsrc%5Etfw">July 3, 2018</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

## Favorite meme
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">I decided to get in on the sick meme action <a href="https://t.co/VCWjc4ZXQd">pic.twitter.com/VCWjc4ZXQd</a></p>&mdash; Geoffrey (@GarrulousGeoff) <a href="https://twitter.com/GarrulousGeoff/status/981708825873997824?ref_src=twsrc%5Etfw">April 5, 2018</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<hr>

That's all for this digest! If you are not subscribed and liked this, feel free to subscribe below!




