---
title: "Last Week in AI #75"
excerpt: "AI for modeling, \"bias-free\" AI hiring, and more!"
image: 
  feature: assets/img/digests/75/rosebud.png
  credit: <a href="https://www.rosebud.ai/#press"> Rosebud AI </a>
categories: [digests]
permalink: /digests/the-seventy-fifth
sidebartoc: true
---

### Mini Briefs

#### [I Am a Model and I Know That Artificial Intelligence Will Eventually Take My Job](https://www.vogue.com/article/sinead-bovell-model-artificial-intelligence)

The Covid-19 pandemic is accelerating automation trends in many fields, and fashion modeling is one of them.
Digital models have existed for awhile, but until recently they were all hand-crafted.
Advances in Generative Adversarial Networks (GANs) and other machine learning techniques for generating realistic human avatars have made digital models a lot more flexible and accessible to modeling agencies and fashion businesses.

While widespread use of digital models can help reduce the carbon footprint of photoshoots and potentially make modeling more inclusive, they also risk making modeling less authentic and diminishing the recent progress human models have made in "chang\[ing\] the perception that \[they\] are just a sample size or a prop for clothes."

In any case, with the Covid-19 pandemic, digital models have become "necessary and needed," and "it would seem to be only a matter of time until fashion giants jump on board."

#### [An AI hiring startup promising bias-free results wants to predict job-hopping](https://www.technologyreview.com/2020/07/24/1005602/ai-hiring-promises-bias-free-job-hopping-prediction/)

Companies that sell algorithmic job screening tools commonly tout how their product is able to correct for human biases.
The argument is that in comparison to humans, algorithms can be more easily "tested and tweaked" against different measures of bias.
A lack of thorough peer-reviewed studies on existing algorithmic hiring tools make such claims hard to verify.
Further, the industry's strong emphasis on bias-mitigatation may be hiding other potential issues.
For example, predictive hiring companies are offering personality tests that "screen out potential employees who have a higher likelihood of agitating for increased wages or supporting unionization."
Notwithstanding the effects on wage depression such practices may have, personality tests themselves are highly contentious and lack adequate regulations.

> The goal of making hiring work better for everyone is a noble one and could be achieved if regulators mandate greater transparency. Currently none of them have received rigorous, peer-reviewed evaluation

### Podcast

Check out our weekly podcast covering these stories!
[Website](https://aitalk.podbean.com) \|
[RSS](https://feed.podbean.com/aitalk/feed.xml) \| 
[iTunes](https://podcasts.apple.com/us/podcast/lets-talk-ai/id1502782720) \|
[Spotify](https://open.spotify.com/show/17HiNdxcoKJLLNibIAyUch) \| 
[YouTube](https://www.youtube.com/channel/UCKARTq-t5SPMzwtft8FWwnA)
<iframe title="Let's Talk AI" id="multi_iframe" class="podcast_embed"
 src="https://www.podbean.com/media/player/multi?playlist=http%3A%2F%2Fplaylist.podbean.com%2F7703921%2Fplaylist_multi.xml&vjs=1&kdsowie31j4k1jlf913=4975ccdd28d39e38bf5a1ccaf0c6ca4337fa996b&size=430&skin=9&episode_list_bg=%23ffffff&bg_left=%23000000&bg_mid=%230c5056&bg_right=%232a1844&podcast_title_color=%23c4c4c4&episode_title_color=%23ffffff&auto=0&share=1&fonts=Helvetica&download=0&rtl=0&show_playlist_recent_number=10&pbad=1" 
 scrolling="yes" allowfullscreen="" width="100%" height="330" frameborder="0"></iframe>

### News
#### Advances & Business

* [Wyze will try pay-what-you-want model for its AI-powered person detection](https://www.theverge.com/2020/7/20/21331974/wyze-cam-ai-person-detection-free-pay-what-you-want-model-experiment) - Smart home company Wyze is experimenting with a rather unconventional method for providing customers with artificial intelligence-powered person detection for its smart security cameras: a pay-what-you want business model.

* [Popular Microsoft Chatbot Xiaoice Gain Independence as a New Company Led by Di Li and Harry Shum](https://medium.com/syncedreview/popular-microsoft-chatbot-xiaoice-migrates-to-new-company-led-by-di-li-and-harry-shum-737e9c6c61cd) - This week, Microsoft announced it would spin off its chatbot business XiaoIce, with all associated technologies licensed to a newly formed independent company. Microsoft says it will maintain an investment interest in the company. Microsoft launched XiaoIce in 2014.

* [Jibo, the social robot that was supposed to die, is getting a second life](https://www.theverge.com/2020/7/23/21325644/jibo-social-robot-ntt-disruptionfunding) - NTT Disruption is keeping Jibo alive

* [CMU and Facebook AI Research use machine learning to teach robots to navigate by recognizing objects](https://techcrunch.com/2020/07/20/cmu-and-facebook-ai-research-use-machine-learning-to-teach-robots-to-navigate-by-recognizing-objects/) - Carnegie Mellon today showed off new research into the world of robotic navigation. With help from the team at Facebook AI Research (FAIR), the university has designed a semantic navigation that helps robots navigate around by recognizing familiar objects.

* [Facebook is simulating users' bad behavior using AI](https://www.theverge.com/2020/7/23/21333854/facebook-ai-simulation-bad-behavior-ww-web-base-simulator) - Facebook's engineers have developed a new method to help them identify and prevent harmful behavior like users spreading spam, scamming others, or buying and selling weapons and drugs.

* [These young immigrant brothers are teaching A.I. to high-schoolers for free: We want to give kids 'a lucky break'](https://www.cnbc.com/2020/07/20/ai-for-anyone-founders-teaching-ai-to-students-for-free-to-give-back.html) - Twenty-something brothers Haroon and Hamza Choudery, came to the US from a remote village in Pakistan two decades ago. They have started an educational start-up, A.I. for Anyone, to give something back.

#### Concerns & Hype

* [Predictive policing algorithms are racist. They need to be dismantled.](https://www.technologyreview.com/2020/07/17/1005396/predictive-policing-algorithms-racist-dismantled-machine-learning-bias-criminal-justice/) - Lack of transparency and biased training data mean these tools are not fit for purpose. If we can't fix them, we should ditch them.

* [The Microsoft Police State: Mass Surveillance, Facial Recognition, and the Azure Cloud](https://theintercept.com/2020/07/14/microsoft-police-state-mass-surveillance-facial-recognition/) - Microsoft, which has largely escaped criticism, is knee-deep in services for law enforcement, fostering an ecosystem of companies that provide police with software using Microsoftâ€™s cloud and other platforms.

* [A Nixon Deepfake, a "Moon Disaster" Speech and an Information Ecosystem at Risk](https://www.scientificamerican.com/article/a-nixon-deepfake-a-moon-disaster-speech-and-an-information-ecosystem-at-risk1/) - A new video re-creates a history that never happened, showing the power of AI-generated media

* [The Record Industry Is Going After Parody Songs Written By an Algorithm](https://www.vice.com/en_us/article/m7jpp3/the-record-industry-is-going-after-parody-songs-written-by-an-algorithm) - Georgia Tech researcher Mark Riedl didn't expect that his machine learning model "Weird A.I. Yancovic," which generates new rhyming lyrics for existing songs would cause any trouble. But it did.

* [GPT-3 Is Amazing - And Overhyped](https://www.forbes.com/sites/robtoews/2020/07/19/gpt-3-is-amazingand-overhyped/) - It is important for the technology community to have a more clear-eyed view of what GPT-3 can and cannot do.

* [Did a Person Write This Headline, or a Machine?](https://www.wired.com/story/ai-text-generator-gpt-3-learning-language-fitfully/) - GPT-3, a new text-generating program from OpenAI, shows how far the field has come - and how far it has to go.

<hr>

That's all for this week! If you are not subscribed and liked this, feel free to subscribe below!
